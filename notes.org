* Conversations
** <2020-03-04 Wed> 
*** Relative paths in experimenter
    Need to check option first
** <2020-03-13 Fri> 
*** Make preprocessing set
*** Clustering next
* Report
**  Exploratory Data Analysis
   Describe here the reasoning you followed for your data exploration. Illustrate the most critical aspects of your exploration with figures / screenshots. You may also use tables and other data summarization resources to present the results of your exploration of the data set.
*** Missing data
**** Fields
     | Attribute  | ? Occurences |
     |------------+--------------|
     | kf9.1      | 22,513 (75%) |
     | blosson2.1 | 27,010 (90%) |
**** Records
     From ~CWData_train.arff~
     #+begin_src
 7276:LNNYDAENKLNDXLL,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,Negative
19785:NDXLLIQLSSPANLS,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,Negative
21401:VFLNNYDAENKLNDX,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,Negative
28158:NYDAENKLNDXLLIQ,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,Negative
29885:RGDLAHLTTTHAXHL,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,Positive
29995:VFLNNYDAENKLNDX,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,Negative
     #+end_src
*** TODO How were the IDs generated?
    Or do they related to the protein sequences themselves?
*** Duplicate
     Loads of duplicates
**** Weird behaviour
     #+begin_src 
 6 matches for "QFPGFKEVRLVPGRH" in buffer: train.arff<preprocessing>
     717:QFPGFKEVRLVPGRH,-0.226,-0.150667,0.076,0.124667,0.018,0.07,0.094,0.159333,-0.340667,0.361333,0.064,?       ,0.223333,-0.030667,-0.112,-0.588667,0.227333,0.218,-0.435867,-0.143467,-0.007933,0.2756,0.378533,0.218733,-3.716667,-0.042,-0.38,-0.084,0.416,-0.048,-0.005333,-0.032667,0.251333,0.217333,-0.234,0.43,0.360667,-0.608667,-0.134,0.71,0.437333,-0.506,0.197333,-0.032,-0.129333,-0.736933,-0.070733,0.054867,-0.042933,-0.398333,-0.248467,0.265533,0.4064,0.2,?,-0.226667,-0.131333,-0.126667,-0.058,0.33,0.16,0.053333,-0.095333,-0.151333,0.453333,-0.214667,Negative
    2175:QFPGFKEVRLVPGRH,-0.226,-0.150667,0.076,0.124667,0.018,0.07,0.094,0.159333,-0.340667,0.361333,0.064,?       ,0.223333,-0.030667,-0.112,-0.588667,0.227333,0.218,-0.435867,-0.143467,-0.007933,0.2756,0.378533,0.218733,-3.716667,-0.042,-0.38,-0.084,0.416,-0.048,-0.005333,-0.032667,0.251333,0.217333,-0.234,0.43,0.360667,-0.608667,-0.134,0.71,0.437333,-0.506,0.197333,-0.032,-0.129333,-0.736933,-0.070733,0.054867,-0.042933,-0.398333,-0.248467,0.265533,0.4064,0.2,?,-0.226667,-0.131333,-0.126667,-0.058,0.33,0.16,0.053333,-0.095333,-0.151333,0.453333,-0.214667,Negative
    2330:QFPGFKEVRLVPGRH,-0.226,-0.150667,0.076,0.124667,0.018,0.07,0.094,0.159333,-0.340667,0.361333,0.064,?       ,0.223333,-0.030667,-0.112,-0.588667,0.227333,0.218,-0.435867,-0.143467,-0.007933,0.2756,0.378533,0.218733,-3.716667,-0.042,-0.38,-0.084,0.416,-0.048,-0.005333,-0.032667,0.251333,0.217333,-0.234,0.43,0.360667,-0.608667,-0.134,0.71,0.437333,-0.506,0.197333,-0.032,-0.129333,-0.736933,-0.070733,0.054867,-0.042933,-0.398333,-0.248467,0.265533,0.4064,0.2,?,-0.226667,-0.131333,-0.126667,-0.058,0.33,0.16,0.053333,-0.095333,-0.151333,0.453333,-0.214667,Negative
    6681:QFPGFKEVRLVPGRH,-0.226,-0.150667,0.076,0.124667,0.018,0.07,0.094,0.159333,-0.340667,0.361333,0.064,?       ,0.223333,-0.030667,-0.112,-0.588667,0.227333,0.218,-0.435867,-0.143467,-0.007933,0.2756,0.378533,0.218733,-3.716667,-0.042,-0.38,-0.084,0.416,-0.048,-0.005333,-0.032667,0.251333,0.217333,-0.234,0.43,0.360667,-0.608667,-0.134,0.71,0.437333,-0.506,0.197333,-0.032,-0.129333,-0.736933,-0.070733,0.054867,-0.042933,-0.398333,-0.248467,0.265533,0.4064,0.2,?,-0.226667,-0.131333,-0.126667,-0.058,0.33,0.16,0.053333,-0.095333,-0.151333,0.453333,-0.214667,Negative
   25417:QFPGFKEVRLVPGRH,-0.226,-0.150667,0.076,0.124667,0.018,0.07,0.094,0.159333,-0.340667,0.361333,0.064,0.122667,0.223333,-0.030667,-0.112,-0.588667,0.227333,0.218,-0.435867,-0.143467,-0.007933,0.2756,0.378533,0.218733,-3.716667,-0.042,-0.38,-0.084,0.416,-0.048,-0.005333,-0.032667,0.251333,0.217333,-0.234,0.43,0.360667,-0.608667,-0.134,0.71,0.437333,-0.506,0.197333,-0.032,-0.129333,-0.736933,-0.070733,0.054867,-0.042933,-0.398333,-0.248467,0.265533,0.4064,0.2,?,-0.226667,-0.131333,-0.126667,-0.058,0.33,0.16,0.053333,-0.095333,-0.151333,0.453333,-0.214667,Positive
   29518:QFPGFKEVRLVPGRH,-0.226,-0.150667,0.076,0.124667,0.018,0.07,0.094,0.159333,-0.340667,0.361333,0.064,0.122667,0.223333,-0.030667,-0.112,-0.588667,0.227333,0.218,-0.435867,-0.143467,-0.007933,0.2756,0.378533,0.218733,-3.716667,-0.042,-0.38,-0.084,0.416,-0.048,-0.005333,-0.032667,0.251333,0.217333,-0.234,0.43,0.360667,-0.608667,-0.134,0.71,0.437333,-0.506,0.197333,-0.032,-0.129333,-0.736933,-0.070733,0.054867,-0.042933,-0.398333,-0.248467,0.265533,0.4064,0.2,?,-0.226667,-0.131333,-0.126667,-0.058,0.33,0.16,0.053333,-0.095333,-0.151333,0.453333,-0.214667,Negative
     #+end_src

***** After using ~weka.filters.unsupervised.instance.RemoveDuplicates~
       #+begin_src 
  3 matches for "QFPGFKEVRLVPGRH" in buffer: remove_dup.arff
      714:QFPGFKEVRLVPGRH,-0.226,-0.150667,0.076,0.124667,0.018,0.07,0.094,0.159333,-0.340667,0.361333,0.064,?       ,0.223333,-0.030667,-0.112,-0.588667,0.227333,0.218,-0.435867,-0.143467,-0.007933,0.2756,0.378533,0.218733,-3.716667,-0.042,-0.38,-0.084,0.416,-0.048,-0.005333,-0.032667,0.251333,0.217333,-0.234,0.43,0.360667,-0.608667,-0.134,0.71,0.437333,-0.506,0.197333,-0.032,-0.129333,-0.736933,-0.070733,0.054867,-0.042933,-0.398333,-0.248467,0.265533,0.4064,0.2,?,-0.226667,-0.131333,-0.126667,-0.058,0.33,0.16,0.053333,-0.095333,-0.151333,0.453333,-0.214667,Negative
    21692:QFPGFKEVRLVPGRH,-0.226,-0.150667,0.076,0.124667,0.018,0.07,0.094,0.159333,-0.340667,0.361333,0.064,0.122667,0.223333,-0.030667,-0.112,-0.588667,0.227333,0.218,-0.435867,-0.143467,-0.007933,0.2756,0.378533,0.218733,-3.716667,-0.042,-0.38,-0.084,0.416,-0.048,-0.005333,-0.032667,0.251333,0.217333,-0.234,0.43,0.360667,-0.608667,-0.134,0.71,0.437333,-0.506,0.197333,-0.032,-0.129333,-0.736933,-0.070733,0.054867,-0.042933,-0.398333,-0.248467,0.265533,0.4064,0.2,?,-0.226667,-0.131333,-0.126667,-0.058,0.33,0.16,0.053333,-0.095333,-0.151333,0.453333,-0.214667,Positive
    24713:QFPGFKEVRLVPGRH,-0.226,-0.150667,0.076,0.124667,0.018,0.07,0.094,0.159333,-0.340667,0.361333,0.064,0.122667,0.223333,-0.030667,-0.112,-0.588667,0.227333,0.218,-0.435867,-0.143467,-0.007933,0.2756,0.378533,0.218733,-3.716667,-0.042,-0.38,-0.084,0.416,-0.048,-0.005333,-0.032667,0.251333,0.217333,-0.234,0.43,0.360667,-0.608667,-0.134,0.71,0.437333,-0.506,0.197333,-0.032,-0.129333,-0.736933,-0.070733,0.054867,-0.042933,-0.398333,-0.248467,0.265533,0.4064,0.2,?,-0.226667,-0.131333,-0.126667,-0.058,0.33,0.16,0.053333,-0.095333,-0.151333,0.453333,-0.214667,Negative
      #+end_src
**** Few ids with many dupes
     6324 IDs with 2+ records
***** Extremes
      After 9 freq, next highest is 61
     | ID              | Freq |
     |-----------------+------|
     | VLDQVLDYVPWIGNG |   71 |
     | DQVLDYVPWIGNGYR |   70 |
     | GSVLDQVLDYVPWIG |   69 |
     | LVGSVLDQVLDYVPW |   68 |
     | FNLVGSVLDQVLDYV |   61 |
***** After remove dupes
      4069 IDs with 2+ records
****** Different not just coz of class
       585 with 3+ records
***** After remove attrs and dupes
      1413 IDs with 2 records
****** [#A] Records with same ID are similiar
       Share same attributes, except:
       * May have missing values in kf9.1 & blosson2.1
       * Different class
***** [#B] After ~RemoveDuplicates~ on sanitised records
      0 IDs with 2 or more records!
****** Sanitised by removing...
       ~weka.filters.unsupervised.attribute.Remove -R 13,56,last~
       * KF9.1
       * BLOSUM2.1
       * Class
**** All dupes only have missing value or class differences
     Proved by finding class distribution is 1 pos & 1 neg for the duplicate records in the removed attributes set.
*** Outliers
**** Using ~weka.filters.unsupervised.attribute.InterquartileRange -R first-last -O 3.0 -E 6.0~
     Default settings
***** Math
 #+begin_src 
 Outliers:
   Q3 + OF*IQR < x <= Q3 + EVF*IQR
   or
   Q1 - EVF*IQR <= x < Q1 - OF*IQR

 Extreme values:
   x > Q3 + EVF*IQR
   or
   x < Q1 - EVF*IQR

 Key:
   Q1  = 25% quartile
   Q3  = 75% quartile
   IQR = Interquartile Range, difference between Q1 and Q3
   OF  = Outlier Factor
   EVF = Extreme Value Factor
 #+end_src
***** Results
      * 746 outliers (i.e. boundary +/- 3*IQR to 6*IQR)
      * No extreme values (i.e. beyond 6*IQR)
****** Fancy set
      * 242 negative, 192 positive
        * vs 13100 neg, 6400 pos
*** Ranges
    * Small
    * negative to positive
*** TODO Fancy stuff
**  Data Preprocessing
   Describe here your data preprocessing. You may want to briefly mention any preprocessing ideas that you tried but didn’t end up using, but focus on those preprocessing activities that eventually became part of your final analysis. The reasoning behind your data preprocessing choices should be clear. You may also summarise the specific steps it in a table (particularly if you used different data preprocessing for different models), or illustrate some of your preprocessing steps with figures / screenshots.
*** Steps
**** Fancy remove
     Reconstructing data using analysis stuff
**** Remove 434 outliers
     * ~weka.filters.unsupervised.attribute.InterquartileRange -R 2-12,14-55,57-66 -O 3.0 -E 6.0 -do-not-check-capabilities~
       * x < Q1 - 3*IQR
       * x > Q3 + 3*IQR
     * ~weka.filters.unsupervised.instance.RemoveWithValues -S 0.0 -C 69 -L last~
     * ~weka.filters.unsupervised.attribute.Remove -R 69-70~
***** Or chain it
      ~weka.filters.MultiFilter -F "weka.filters.unsupervised.attribute.InterquartileRange -R 2-12,14-55,57-66 -O 3.0 -E 6.0 -do-not-check-capabilities" -F "weka.filters.unsupervised.instance.RemoveWithValues -S 0.0 -C 69 -L last" -F "weka.filters.unsupervised.attribute.Remove -R 69-70"~
*** Filtering
***** Remove ID, KF9.1 &  BLOSUM2.1
      ~weka.filters.unsupervised.attribute.Remove -R 1,13,56~
***** AttributeSelection
      ~weka.filters.supervised.attribute.AttributeSelection -E "weka.attributeSelection.PrincipalComponents -R 0.95 -A 5" -S "weka.attributeSelection.Ranker -T -1.7976931348623157E308 -N -1"~
****** Evauator
       ~weka.attributeSelection.PrincipalComponents -R 0.95 -A 5~
****** Search
       ~weka.attributeSelection.Ranker -T -1.7976931348623157E308 -N -1~
**** MultiFilter
     ~weka.filters.MultiFilter -F "weka.filters.unsupervised.attribute.Remove -R 1,13,56" -F "weka.filters.supervised.attribute.AttributeSelection -E \"weka.attributeSelection.PrincipalComponents -R 0.95 -A 5\" -S \"weka.attributeSelection.Ranker -T -1.7976931348623157E308 -N -1\""~
**** FilteredClassifier using AttributeSelectedClassifer
     ~weka.classifiers.meta.FilteredClassifier -F "weka.filters.unsupervised.attribute.Remove -R 1,13,56" -S 1 -W weka.classifiers.meta.AttributeSelectedClassifier -- -E "weka.attributeSelection.PrincipalComponents -R 0.95 -A 5" -S "weka.attributeSelection.Ranker -T -1.7976931348623157E308 -N -1" -W weka.classifiers.lazy.IBk -- -K 1 -W 0 -A "weka.core.neighboursearch.LinearNNSearch -A \"weka.core.EuclideanDistance -R first-last\""~
**** FilteredClusterer example
     ~weka.clusterers.FilteredClusterer -F "weka.filters.MultiFilter -F \"weka.filters.unsupervised.attribute.Remove -R 1,13,56\" -F \"weka.filters.supervised.attribute.AttributeSelection -E \\\"weka.attributeSelection.PrincipalComponents -R 0.95 -A 5\\\" -S \\\"weka.attributeSelection.Ranker -T -1.7976931348623157E308 -N -1\\\"\"" -W weka.clusterers.SimpleKMeans -- -init 0 -max-candidates 100 -periodic-pruning 10000 -min-density 2.0 -t1 -1.25 -t2 -1.0 -N 2 -A "weka.core.EuclideanDistance -R first-last" -I 1 -num-slots 1 -S 10~
** Models
*** NaiveBayes
*** kNN
**** TODO Does it normalise automatically?
*** RandomForests
*** j48
*** ZeroR
*** Logistical Regression
**  Modelling: equal-costs classification
   Describe here the models that you have explored for the equal-costs classification task. It is useful to have some sort of general performance baseline (the accuracy of the default “zero-rule” or of the simple 1-rule classifier are often useful ones), as well as a per-model baseline - e.g., the performance of the models under their standard parameter values on the raw data as well as on the preprocessed data. Again, tables are usually a great way of summarizing this information. 
   Here is also the place where you discuss your model tuning, and select the single model you have selected at the end of the model exploration. Discuss the reasons behind your choice of model, how you evaluated model performance in the training stage, and what performance gains were observed over the baseline(s) used. If you encapsulated your preprocessing steps into the model structure using a Filtered Classifier, please state it explicitly.
**  Modelling: cost-sensitive classification
   Describe here the models that you have explored for the cost-sensitive classification task. You must explicitly show the cost matrix that you have used. As in the previous section, it is useful to have some sort of general performance baseline (in terms of cost), as well as a per-model baseline. Discuss any tuning you may have performed specifically for the cost-sensitive models, and select the single model you have selected at the end of the model exploration. Discuss the reasons behind your choice of model, how you evaluated model performance in the training stage, and what performance gains were observed over the baseline(s) used. If you encapsulated your preprocessing steps into the model structure using a Filtered Classifier, please state it explicitly.
**  Final performance
   Add a table here summarizing the performance observed on the final (test) set, for both the equal-costs and the cost-sensitive cases. 
**  Conclusions
   A short conclusion discussing your findings and results.
**  References
